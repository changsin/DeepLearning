{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UFPR-License-Plate-dataset.ipynb",
      "provenance": [],
      "mount_file_id": "1B6k834f69h1QOeq3hXcf-s-8XSzH2ORz",
      "authorship_tag": "ABX9TyOsljGgQEd+Ti3rtXNlF/sl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/FSDL/blob/main/notebooks/UFPR_License_Plate_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY4OkIZTqRIU"
      },
      "source": [
        "# Brazilean license plate dataset\n",
        "\n",
        "The dataset came from: https://web.inf.ufpr.br/vri/databases/ufpr-alpr/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ2-8oKLaAUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbab5ca-d842-490e-bfee-92da4b9183ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_ROOT = \"./drive/MyDrive/data/UFPR_YOLO\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Elp-_sazQmKG",
        "outputId": "5b0fda10-946b-4907-ec38-2976dee3ab95"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 29.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 39.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.1MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvWkllBpMC75"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2OUMvgoTvRx"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Umzen5aPbN"
      },
      "source": [
        "IMAGE_SIZE = 224"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tQVhQUIbTRa"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNFjvU_EnlcV"
      },
      "source": [
        "def load_images(path):\n",
        "  path = os.path.join(path,'*')\n",
        "  files = glob.glob(path)\n",
        "  # We sort the images in alphabetical order to match them\n",
        "  #  to the annotation files\n",
        "  files.sort()\n",
        "\n",
        "  X_raw = []\n",
        "  for f1 in files:\n",
        "    image = cv2.imread(f1)\n",
        "    image = cv2.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
        "    X_raw.append(np.array(image))\n",
        "\n",
        "  return X_raw\n",
        "\n",
        "def load_labels(path):\n",
        "  path = os.path.join(path,'*')\n",
        "  files = glob.glob(path)\n",
        "  files.sort()\n",
        "\n",
        "  y_raw = []\n",
        "  for file in files:\n",
        "      y_raw.append(extract_annotations(file, 0))\n",
        "  return y_raw"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAb2E6R3iTiA"
      },
      "source": [
        "def extract_annotations(label_file, class_id):\n",
        "  labels = []\n",
        "  with open(label_file, \"r\") as file:\n",
        "    count = 0\n",
        "    for line in file:\n",
        "      tokens = [float(token) for token in line.split()]\n",
        "      if tokens[0] == class_id:\n",
        "        count += 1\n",
        "        # print(line)\n",
        "        labels.append(np.array(tokens[1:]))\n",
        "\n",
        "    if count > 1:\n",
        "      print(\"WARNING: More than one license plate was found: \", count, label_file)\n",
        "    elif count == 0:\n",
        "      print(\"WARNING: No license plate was found: \", count, label_file)\n",
        "\n",
        "  return np.array(labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enXm7FVGhy_m"
      },
      "source": [
        "# transform to arrays and normalize\n",
        "def normalize(X_raw, y_raw):\n",
        "  X = np.array(X_raw)\n",
        "  y = np.array(y_raw)\n",
        "  y = y.reshape((y.shape[0], -1))\n",
        "\n",
        "  #  Renormalisation\n",
        "  X = X / IMAGE_SIZE\n",
        "  y = y / IMAGE_SIZE\n",
        "\n",
        "  return X, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_3kpZPEiXXQ"
      },
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "def create_patch_rectangle(y, color):\n",
        "  # width = y[2] - y[0]\n",
        "  # height = y[3] - y[1]\n",
        "  # return patches.Rectangle((y[0], y[1]),\n",
        "  #                           width, height,\n",
        "  #                           edgecolor=color, fill=False)\n",
        "  # # in yolov5\n",
        "  width = int(y[2])\n",
        "  height = int(y[3])\n",
        "  return patches.Rectangle((int(y[0] - width/2), int(y[1] - height/2)),\n",
        "                           width, height,\n",
        "                           edgecolor=color, fill=False)\n",
        "def plot_images(X, y, limit=10):\n",
        "  fig = plt.figure(figsize=(20,40))\n",
        "\n",
        "  # The number of images for plotting is limited to 50\n",
        "  end_id = len(y) if len(y) < limit else limit\n",
        "\n",
        "  for i in range(0, end_id):\n",
        "    axis = fig.add_subplot(10, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    image = X[i]\n",
        "\n",
        "    rect_ori = create_patch_rectangle(y[i]*IMAGE_SIZE, (0, 255/255, 0))\n",
        "    axis.add_patch(rect_ori)\n",
        "    plt.imshow(np.clip(image, 0, 1))\n",
        "# plot_images(X_train_d[0], y_train_d[0])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JRji1gUTr9G"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6up3SdpzRaIt"
      },
      "source": [
        "X_train_raw = load_images(DATA_ROOT + \"/images/train/\")\n",
        "# X_test_raw = load_images(DATA_ROOT + \"/images/test/\")\n",
        "# X_val_raw = load_images(DATA_ROOT + \"/images/validation/\")\n",
        "\n",
        "y_train_raw = load_labels(DATA_ROOT + \"/labels/train/\")\n",
        "# y_val_raw = load_labels(DATA_ROOT + \"/labels/validation/\")\n",
        "# y_test_raw = load_labels(DATA_ROOT + \"/labels/test/\")\n",
        "\n",
        "\n",
        "# # from sklearn.model_selection import train_test_split\n",
        "# # TODO\n",
        "# X_train_raw = X_raw\n",
        "\n",
        "X_train, y_train = normalize(X_train_raw, y_train_raw)\n",
        "# X_val, y_val = normalize(X_val_raw, y_val_raw)\n",
        "# X_test, y_test = normalize(X_test_raw, y_test_raw)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXlK0eGjL-0R"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvTRFJuGPEVV"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7uFtCraWspu"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing  # to normalise existing X\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "dist = tfp.distributions\n",
        "\n",
        "# from keras.preprocessing import image\n",
        "# from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "#Calculate similar matrics\n",
        "def cosine_similarity(ratings):\n",
        "    sim = ratings.dot(ratings.T)\n",
        "    if not isinstance(sim,np.ndarray):\n",
        "        sim = sim.toarray()\n",
        "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
        "    return (sim/norms/norms.T)\n",
        "\n",
        "def get_feature_maps(input):\n",
        "    # #Convert to VGG input format\n",
        "    # NB: This messes up the existing data so skipping it\n",
        "    #   similarity measures do not seem to be affected by this.\n",
        "    # vgg_input = preprocess_input(input)\n",
        "\n",
        "    #include_top=False == not getting VGG16 last 3 layers\n",
        "    model = VGG16(weights = \"imagenet\", include_top=False)\n",
        "\n",
        "    #Get features\n",
        "    # feature_maps = model.predict(vgg_input)\n",
        "    feature_maps = model.predict(input)\n",
        "\n",
        "    return feature_maps, model\n",
        "\n",
        "    # #Calculate similar metrics\n",
        "    # features_compress = features.reshape(len(y_test), 7*7*512)\n",
        "    # sim = cosine_similarity(features_compress)\n",
        "\n",
        "# model_vgg16, feature_maps = get_feature_maps(X)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32f6Yv9fbI6t"
      },
      "source": [
        "def find_clusters(X_np, K):\n",
        "  fm_x, _ = get_feature_maps(X_np)\n",
        "  # use cosine distance to find similarities\n",
        "  fm_x_normalized = preprocessing.normalize(fm_x.reshape(len(fm_x), -1))\n",
        "\n",
        "  clusters_x = KMeans(n_clusters=K, random_state=0).fit(fm_x_normalized)\n",
        "  histo_x, bins = np.histogram(clusters_x.labels_, bins=range(K + 1))\n",
        "\n",
        "  # plt.hist(bins[:-1], bins, weights=histo_x, histtype='step', label='x')\n",
        "  plt.bar(bins[:-1], histo_x, align='center')\n",
        "\n",
        "  return clusters_x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6YXiTV8oTS8"
      },
      "source": [
        "def to_cluster_ids(bins, labels):\n",
        "  cluster_dict = dict()\n",
        "  for cluster_id in bins:\n",
        "    cluster_dict[cluster_id] = np.where(labels == cluster_id)[0]\n",
        "  return cluster_dict"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLYBVozhbnYm"
      },
      "source": [
        "def to_clusters_dict(X, y, K):\n",
        "  X_clusters = find_clusters(X, K)\n",
        "  X_cluster_ids = to_cluster_ids(range(K), X_clusters.labels_)\n",
        "\n",
        "  X_dict = {}\n",
        "  y_dict = {}\n",
        "  for id in range(K):\n",
        "    ids = X_cluster_ids[id]\n",
        "    X_dict[id] = X[ids]\n",
        "    y_dict[id] = y[ids]\n",
        "\n",
        "  return X_dict, y_dict\n",
        "\n",
        "# merge all clusters to return the data\n",
        "def get_merged_data(clusters_d):\n",
        "  merged = []\n",
        "  for id, data in clusters_d.items():\n",
        "    merged = data if id == 0 else np.vstack((merged, data))\n",
        "  return merged"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXeR0EfTITAb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def partition_on_clusters(X_d, y_d, bins, val_size=0.1, test_size=0.2):\n",
        "  X_train_d = dict()\n",
        "  y_train_d = dict()\n",
        "  X_val_d = dict()\n",
        "  y_val_d = dict()\n",
        "  X_test_d = dict()\n",
        "  y_test_d = dict()\n",
        "\n",
        "  # for each cluster reserve test_size portion for test data\n",
        "  for id in bins:\n",
        "    Xt_train, Xt_test, yt_train, yt_test = \\\n",
        "      train_test_split(X_d[id], y_d[id], test_size=0.2, shuffle=False)\n",
        "    Xt_train, Xt_val, yt_train, yt_val = \\\n",
        "      train_test_split(Xt_train, yt_train, test_size=0.1, shuffle=False)\n",
        "\n",
        "    X_train_d[id] = Xt_train\n",
        "    y_train_d[id] = yt_train\n",
        "\n",
        "    X_val_d[id] = Xt_val\n",
        "    y_val_d[id] = yt_val\n",
        "\n",
        "    X_test_d[id] = Xt_test\n",
        "    y_test_d[id] = yt_test\n",
        "\n",
        "  return X_train_d, y_train_d, \\\n",
        "         X_val_d, y_val_d, \\\n",
        "         X_test_d, y_test_d"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmo2C_ADPLdy"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju22TxeS3Avh"
      },
      "source": [
        "K = 5\n",
        "# bins, cluster_x_counts = np.unique(clusters_x.labels_, return_counts=True)\n",
        "X_train_d, y_train_d = to_clusters_dict(X_train, y_train, K)\n",
        "# X_val_d, y_val_d = to_clusters_dict(X_val, y_val, K)\n",
        "# X_test_d, y_test_d = to_clusters_dict(X_test, y_test, K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXg46UsiM9Za"
      },
      "source": [
        "X_train_d, y_train_d, X_val_d, y_val_d, X_test_d, y_test_d = \\\n",
        "          partition_on_clusters(X_train_d, y_train_d, range(K))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-jYzEkKXJSR"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8L1sXD0XQ6V"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyYc1vcvXPQx"
      },
      "source": [
        "def create_model(train_size, probability=True):\n",
        "  kl_divergence_fn = lambda q, p, _: dist.kl_divergence(q, p) / tf.cast(y_train.shape[0], dtype=tf.float32)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dense(128, activation=\"relu\"))\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "\n",
        "  if probability:\n",
        "    model.add(tfp.layers.DenseFlipout(4, activation=\"sigmoid\", kernel_divergence_fn=kl_divergence_fn))\n",
        "  else:\n",
        "    model.add(Dense(4, activation=\"sigmoid\"))\n",
        "\n",
        "  model.layers[-6].trainable = False\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JouyxJzXXSip"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz3y42knXUi3"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyXG45TZXyZm"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ_jK7qRXWNj"
      },
      "source": [
        "def train(model,\n",
        "          X_train, y_train,\n",
        "          X_val, y_val,\n",
        "          X_test, y_test,\n",
        "          epochs=50, batch_size=16,\n",
        "          is_plot_predictions=False):\n",
        "  train_history = model.fit(x=X_train, y=y_train,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            epochs=epochs, batch_size=batch_size, verbose=1,\n",
        "                            callbacks=[wandb.keras.WandbCallback(data_type=\"image\",\n",
        "                            save_model=False)])\n",
        "  # Test\n",
        "  scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Score : %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(X_test, y_test, steps=int(100))\n",
        "\n",
        "  print(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)\n",
        "\n",
        "  y_preds = sample_predictions(model, X_test, iterations=1)\n",
        "  # y_preds = model.predict(X_test)\n",
        "\n",
        "  # # TODO:\n",
        "  # # Hack to fix erroneous predictions\n",
        "  # y_preds = fix_predictions(y_preds)\n",
        "  if is_plot_predictions:\n",
        "    plot_predictions(X_test, y_test, y_preds)\n",
        "\n",
        "  # averaged_predictions = average_sample_preds(y_preds)\n",
        "  # y_test = np.array([to_rect(y*IMAGE_SIZE) for y in y_test])\n",
        "  # rectified_predictions = np.array([to_rect(y*IMAGE_SIZE) for y in averaged_predictions])\n",
        "\n",
        "  # # print(rectified_predictions)\n",
        "  # m_ap = calculate_map(y_test*IMAGE_SIZE, rectified_predictions*IMAGE_SIZE)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQcPSyR5Apn4"
      },
      "source": [
        "### Sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZr7S3eSb-2n"
      },
      "source": [
        "# run predictions many times to get the distributions\n",
        "def sample_predictions(model, samples, iterations=100):\n",
        "    predicted = []\n",
        "    for _ in range(iterations):\n",
        "        predicted.append(model(samples).numpy())\n",
        "\n",
        "    predicted = np.array(predicted)\n",
        "    # predicted = np.concatenate(predicted, axis=1)\n",
        "\n",
        "    # predicted = np.array([model_prob.predict(np.expand_dims(X_test[1], [0])) for i in range(iterations)])\n",
        "    # predicted = np.concatenate(predicted, axis=1)\n",
        "    reshaped = np.array([predicted[:, column] for column in range(0, predicted.shape[1])])\n",
        "\n",
        "    return reshaped\n",
        "\n",
        "def predict_on_cluster(model, X_test, y_test, is_plot_predictions=False, iterations=50):\n",
        "  test_accuracy = 0\n",
        "  test_loss, test_accuracy = model.evaluate(X_test, y_test, steps=1)\n",
        "  y_preds = sample_predictions(model, X_test, iterations=iterations)\n",
        "\n",
        "  # TODO:\n",
        "  # Hack to fix erroneous predictions\n",
        "  # y_preds_fixed = fix_predictions(y_preds)\n",
        "  if is_plot_predictions:\n",
        "    plot_predictions(X_test, y_test, y_preds)\n",
        "\n",
        "  preds_avg = average_sample_preds(y_preds)\n",
        "  rectified_y_test = np.array([to_rect(y*IMAGE_SIZE) for y in y_test])\n",
        "  rectified_predictions = np.array([to_rect(y*IMAGE_SIZE) for y in preds_avg])\n",
        "\n",
        "  m_ap = calculate_map(rectified_y_test*IMAGE_SIZE, rectified_predictions*IMAGE_SIZE)\n",
        "  stds = np.mean(np.std(y_preds, axis=1), axis=1)\n",
        "\n",
        "  return y_preds, m_ap, np.mean(stds, axis=0), test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78iDihi3bPbx"
      },
      "source": [
        "def predict_on_models(X, y, bins, models):\n",
        "  stats = []\n",
        "  for model in models:\n",
        "    cluster_stats = []\n",
        "    for clst_id in bins:\n",
        "      # y_preds, m_ap, accuracy, mstd = predict_on_cluster(model, X[clst_ids[clst_id]], y[clst_ids[clst_id]])\n",
        "      y_preds, m_ap, std, accuracy = predict_on_cluster(model, X[clst_id], y[clst_id])\n",
        "      print(\"{} mAP: {:0.2f} std: {:0.2f} acc: {:0.2f}\".format(clst_id,\n",
        "                                                               m_ap['avg_prec'],\n",
        "                                                               std,\n",
        "                                                               accuracy))\n",
        "      cluster_stats.append([np.round(m_ap['avg_prec'], 3), np.round(std, 3), np.round(accuracy, 3)])\n",
        "\n",
        "    stats.append(cluster_stats)\n",
        "\n",
        "  return np.array(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfi0AX8gX8uf"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVj0vPtmX7W4"
      },
      "source": [
        "X_train = get_merged_data(X_train_d)\n",
        "y_train = get_merged_data(y_train_d)\n",
        "\n",
        "X_val = get_merged_data(X_val_d)\n",
        "y_val = get_merged_data(y_val_d)\n",
        "\n",
        "X_test = get_merged_data(X_test_d)\n",
        "y_test = get_merged_data(y_test_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeYFDS63Rqop"
      },
      "source": [
        "wandb.init(project=\"UFPR-cnn\",\n",
        "           config={\n",
        "               \"batch_size\": 16,\n",
        "               \"learning_rate\": 0.01,\n",
        "               \"dataset\": \"UFPR-cnn\",\n",
        "           })\n",
        "\n",
        "model_cnn = create_model(y_train.shape[0], probability=False)\n",
        "model_cnn = train(model_cnn,\n",
        "                  X_train, y_train,\n",
        "                  X_val, y_val,\n",
        "                  X_test, y_test, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnBI4Y9fR1R-"
      },
      "source": [
        "wandb.init(project=\"UFPR-prob\",\n",
        "           config={\n",
        "               \"batch_size\": 16,\n",
        "               \"learning_rate\": 0.01,\n",
        "               \"dataset\": \"UFPR-prob\",\n",
        "           })\n",
        "\n",
        "model_prob = create_model(y_train.shape[0], probability=True)\n",
        "model_prob = train(model_prob,\n",
        "                   X_train, y_train,\n",
        "                   X_val, y_val,\n",
        "                   X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQQ3Y9FY_YP"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QiLwODlZPXK"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKQgXQ4p8Kyb"
      },
      "source": [
        "### Plot predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZLNEMVCTpCT"
      },
      "source": [
        "def plot_predictions(X, y_gt, y_preds):\n",
        "  fig = plt.figure(figsize=(20,40))\n",
        "\n",
        "  # The number of images for plotting is limited to 50\n",
        "  end_id = len(y_gt) if len(y_gt) < 50 else 50\n",
        "\n",
        "  y_preds_avg = average_sample_preds(y_preds)\n",
        "  stds = np.std(y_preds, axis=1)\n",
        "  mean_stds = np.mean(stds, axis=1)\n",
        "\n",
        "  for i in range(0, end_id):\n",
        "    axis = fig.add_subplot(10, 5, i+1)\n",
        "    plt.axis('off')\n",
        "    image = X[i]\n",
        "\n",
        "    rect_ori = create_patch_rectangle(y_gt[i]*IMAGE_SIZE, (0, 255/255, 0))\n",
        "    axis.add_patch(rect_ori)\n",
        "\n",
        "    # for each test image, there could be multiple predictions\n",
        "    for y_pred in y_preds[i]:\n",
        "      rect_pred = create_patch_rectangle(y_pred*IMAGE_SIZE, (255/255, 0, 0))\n",
        "      axis.add_patch(rect_pred)\n",
        "\n",
        "    iou = bb_iou(to_rect(y_preds_avg[i]*IMAGE_SIZE), to_rect(y_gt[i]*IMAGE_SIZE))\n",
        "    plt.title(\"IOU: {:0.2f} std: {:0.2f}\".format(iou, mean_stds[i]))\n",
        "    # plt.title(\"mean std: {:0.2f}\".format(mean_stds[sample_ids[i]]))\n",
        "    plt.imshow(np.clip(image, 0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMO_P4YTcTFp"
      },
      "source": [
        "def plot_stats(stats, types, titles):\n",
        "  x_bar = np.arange(K)\n",
        "  bar_width = .35\n",
        "\n",
        "  fig = plt.figure(figsize=(20,40))\n",
        "\n",
        "  for i, stat in zip(range(len(stats)), stats):\n",
        "    ax = fig.add_subplot(10, 4, i+1)\n",
        "    # plt.axis('off')\n",
        "\n",
        "    for t in types:\n",
        "      if \"mAP\" == t:\n",
        "        rects1 = ax.bar(x_bar - bar_width/3, stat[:, 0], label=\"mAP\")\n",
        "      if \"std\" == t:\n",
        "        rects2 = ax.bar(x_bar + bar_width/3, stat[:, 1], label=\"std\")\n",
        "      if \"accuracy\" == t:\n",
        "        rects3 = ax.bar(x_bar + bar_width/3, stat[:, 2], label=\"accuracy\")\n",
        "\n",
        "    ax.set_xticks(x_bar)\n",
        "    ax.set_xticklabels(x_bar)\n",
        "    ax.set_title(titles[i])\n",
        "\n",
        "    ax.legend()\n",
        "\n",
        "  fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb6301Qh8JeI"
      },
      "source": [
        "# plot line graph for comparing different noise level results\n",
        "def plot_stats_by_type(stats, x_bins, column, title, clusters=bins, merge=False):\n",
        "  fig = plt.figure(figsize=(20,40))\n",
        "  ax = fig.add_subplot(10, 4, 1)\n",
        "\n",
        "  if merge:\n",
        "    p = ax.plot(x_bins, [np.mean(run) for run in stats_noise[:, :, 1]], label='avg')\n",
        "  else:\n",
        "    x_bins_len = len(x_bins)\n",
        "    for cluster_id in range(len(clusters)):\n",
        "      p = ax.plot(x_bins, stats[:x_bins_len, :, column][:, cluster_id], label=cluster_id)\n",
        "    # p = ax.plot(noise_levels, stats[:bins, :, column][:, 0], color='green', label='0')\n",
        "\n",
        "  ax.set_title(title)\n",
        "  ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LhzE89ZYvL"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLnXXxhjZZ_R"
      },
      "source": [
        "\n",
        "_, m_ap, std, accuracy = predict_on_cluster(model_prob, X_test_d[0], y_test_d[0], is_plot_predictions=True, iterations=100)\n",
        "print(\"{} mAP: {:0.2f} std: {:0.2f} acc: {:0.2f}\".format(0,\n",
        "                                                          m_ap['avg_prec'],\n",
        "                                                          std,\n",
        "                                                          accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}